{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/bqcdtp2s6652tsxqm4hhv4gr0000gn/T/ipykernel_95835/2856144359.py:26: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  torch.Tensor(all_points3d),\n"
     ]
    }
   ],
   "source": [
    "from splat.gaussians import Gaussians\n",
    "from splat.gaussian_scene import GaussianScene\n",
    "import pycolmap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from splat.utils import read_images_text, read_images_binary\n",
    "\n",
    "colmap_path = \"treehill/sparse/0\"\n",
    "reconstruction = pycolmap.Reconstruction(colmap_path)\n",
    "\n",
    "points3d = reconstruction.points3D\n",
    "images = read_images_binary(f\"{colmap_path}/images.bin\")\n",
    "cameras = reconstruction.cameras\n",
    "\n",
    "all_points3d = []\n",
    "all_point_colors = []\n",
    "\n",
    "for idx, point in enumerate(points3d.values()):\n",
    "    if point.track.length() >= 2:\n",
    "        all_points3d.append(point.xyz)\n",
    "        all_point_colors.append(point.color)\n",
    "\n",
    "gaussians = Gaussians(\n",
    "    torch.Tensor(all_points3d),\n",
    "    torch.Tensor(all_point_colors),\n",
    "    model_path=\"point_clouds\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert 3d gaussians to 2d\n",
    "Note: we are only using isotropic gaussians for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fovX: tensor([1.0817]), fovY: tensor([0.7531])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "from splat.utils import (\n",
    "    read_camera_file,\n",
    "    read_image_file,\n",
    "    build_rotation,\n",
    "    in_view_frustum,\n",
    ")\n",
    "\n",
    "\n",
    "def get_extrinsic_matrix(R: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Get the homogenous extrinsic matrix for the camera\n",
    "    \"\"\"\n",
    "    Rt = torch.zeros((4, 4))\n",
    "    Rt[:3, :3] = R\n",
    "    Rt[:3, 3] = t\n",
    "    Rt[3, 3] = 1.0\n",
    "    return Rt\n",
    "\n",
    "\n",
    "def getIntinsicMatrix(\n",
    "    focal_x: torch.Tensor,\n",
    "    focal_y: torch.Tensor,\n",
    "    height: torch.Tensor,\n",
    "    width: torch.Tensor,\n",
    "    zfar: torch.Tensor = torch.Tensor([100.0]),\n",
    "    znear: torch.Tensor = torch.Tensor([0.001]),\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Gets the internal perspective projection matrix\n",
    "\n",
    "    znear: near plane set by user\n",
    "    zfar: far plane set by user\n",
    "    fovX: field of view in x, calculated from the focal length\n",
    "    fovY: field of view in y, calculated from the focal length\n",
    "    \"\"\"\n",
    "    fovX = torch.Tensor([2 * math.atan(width / (2 * focal_x))])\n",
    "    fovY = torch.Tensor([2 * math.atan(height / (2 * focal_y))])\n",
    "    print(f\"fovX: {fovX}, fovY: {fovY}\")\n",
    "\n",
    "    tanHalfFovY = math.tan((fovY / 2))\n",
    "    tanHalfFovX = math.tan((fovX / 2))\n",
    "\n",
    "    top = tanHalfFovY * znear\n",
    "    bottom = -top\n",
    "    right = tanHalfFovX * znear\n",
    "    left = -right\n",
    "\n",
    "    P = torch.zeros(4, 4)\n",
    "\n",
    "    z_sign = 1.0\n",
    "\n",
    "    P[0, 0] = 2.0 * znear / (right - left)\n",
    "    P[1, 1] = 2.0 * znear / (top - bottom)\n",
    "    P[0, 2] = (right + left) / (right - left)\n",
    "    P[1, 2] = (top + bottom) / (top - bottom)\n",
    "    P[3, 2] = z_sign\n",
    "    P[2, 2] = z_sign * zfar / (zfar - znear)\n",
    "    P[2, 3] = -(zfar * znear) / (zfar - znear)\n",
    "    return P\n",
    "\n",
    "\n",
    "def compute_2d_covariance(\n",
    "    points: torch.Tensor,\n",
    "    extrinsic_matrix: torch.Tensor,\n",
    "    covariance_3d: torch.Tensor,\n",
    "    tan_fovY: torch.Tensor,\n",
    "    tan_fovX: torch.Tensor,\n",
    "    focal_x: torch.Tensor,\n",
    "    focal_y: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the 2D covariance matrix for each gaussian\n",
    "    \"\"\"\n",
    "    points = torch.cat(\n",
    "        [points, torch.ones(points.shape[0], 1, device=points.device)], dim=1\n",
    "    )\n",
    "    points_transformed = (points @ extrinsic_matrix)[:, :3]\n",
    "    limx = 1.3 * tan_fovX\n",
    "    limy = 1.3 * tan_fovY\n",
    "    x = points_transformed[:, 0] / points_transformed[:, 2]\n",
    "    y = points_transformed[:, 1] / points_transformed[:, 2]\n",
    "    z = points_transformed[:, 2]\n",
    "    x = torch.clamp(x, -limx, limx) * z\n",
    "    y = torch.clamp(y, -limy, limy) * z\n",
    "\n",
    "    J = torch.zeros((points_transformed.shape[0], 3, 3), device=covariance_3d.device)\n",
    "    J[:, 0, 0] = focal_x / z\n",
    "    J[:, 0, 2] = -(focal_x * x) / (z**2)\n",
    "    J[:, 1, 1] = focal_y / z\n",
    "    J[:, 1, 2] = -(focal_y * y) / (z**2)\n",
    "\n",
    "    # transpose as originally set up for perspective projection\n",
    "    # so we now transform back\n",
    "    W = extrinsic_matrix[:3, :3].T\n",
    "\n",
    "    return (J @ W @ covariance_3d @ W.T @ J.transpose(1, 2))[:, :2, :2]\n",
    "\n",
    "\n",
    "covariance_3d = gaussians.get_3d_covariance_matrix()\n",
    "\n",
    "# we will examine the 100th image\n",
    "image_num = 100\n",
    "image_dict = read_image_file(colmap_path)\n",
    "camera_dict = read_camera_file(colmap_path)\n",
    "\n",
    "# convert quaternion to rotation matrix\n",
    "rotation_matrix = build_rotation(torch.Tensor(image_dict[image_num].qvec).unsqueeze(0))\n",
    "translation = torch.Tensor(image_dict[image_num].tvec).unsqueeze(0)\n",
    "extrinsic_matrix = get_extrinsic_matrix(rotation_matrix, translation)\n",
    "focal_x, focal_y = camera_dict[image_dict[image_num].camera_id].params[:2]\n",
    "c_x, c_y = camera_dict[image_dict[image_num].camera_id].params[2:4]\n",
    "width = camera_dict[image_dict[image_num].camera_id].width\n",
    "height = camera_dict[image_dict[image_num].camera_id].height\n",
    "\n",
    "# note we transpose the intrinsic matrix\n",
    "intrinsic_matrix = getIntinsicMatrix(focal_x, focal_y, height, width).T\n",
    "in_view = in_view_frustum(\n",
    "    points=gaussians.points,\n",
    "    view_matrix=extrinsic_matrix.T,\n",
    ")\n",
    "\n",
    "fovX = torch.Tensor([2 * math.atan(width / (2 * focal_x))])\n",
    "fovY = torch.Tensor([2 * math.atan(height / (2 * focal_y))])\n",
    "\n",
    "\n",
    "covariance_2d = compute_2d_covariance(\n",
    "    points=gaussians.points[in_view],\n",
    "    extrinsic_matrix=extrinsic_matrix.T,\n",
    "    covariance_3d=covariance_3d[in_view],\n",
    "    tan_fovY=torch.tan(fovX / 2),\n",
    "    tan_fovX=torch.tan(fovX / 2),\n",
    "    focal_x=focal_x,\n",
    "    focal_y=focal_y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inverted_covariance(covariance_2d: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the inverse covariance matrix\n",
    "\n",
    "    For a 2x2 matrix\n",
    "    given as\n",
    "    [[a, b],\n",
    "     [c, d]]\n",
    "     the determinant is ad - bc\n",
    "\n",
    "    To get the inverse matrix reshuffle the terms like so\n",
    "    and multiply by 1/determinant\n",
    "    [[d, -b],\n",
    "     [-c, a]] * (1 / determinant)\n",
    "    \"\"\"\n",
    "    determinant = (\n",
    "        covariance_2d[:, 0, 0] * covariance_2d[:, 1, 1]\n",
    "        - covariance_2d[:, 0, 1] * covariance_2d[:, 1, 0]\n",
    "    )\n",
    "    determinant = torch.clamp(determinant, min=1e-3)\n",
    "    inverse_covariance = torch.zeros_like(covariance_2d)\n",
    "    inverse_covariance[:, 0, 0] = covariance_2d[:, 1, 1] / determinant\n",
    "    inverse_covariance[:, 1, 1] = covariance_2d[:, 0, 0] / determinant\n",
    "    inverse_covariance[:, 0, 1] = -covariance_2d[:, 0, 1] / determinant\n",
    "    inverse_covariance[:, 1, 0] = -covariance_2d[:, 1, 0] / determinant\n",
    "    return inverse_covariance\n",
    "\n",
    "\n",
    "def compute_extent_and_radius(covariance_2d: torch.Tensor):\n",
    "    mid = 0.5 * (covariance_2d[:, 0, 0] + covariance_2d[:, 1, 1])\n",
    "    det = covariance_2d[:, 0, 0] * covariance_2d[:, 1, 1] - covariance_2d[:, 0, 1] ** 2\n",
    "    intermediate_matrix = (mid * mid - det).view(-1, 1)\n",
    "    intermediate_matrix = torch.cat(\n",
    "        [intermediate_matrix, torch.ones_like(intermediate_matrix) * 0.1], dim=1\n",
    "    )\n",
    "\n",
    "    max_values = torch.max(intermediate_matrix, dim=1).values\n",
    "    lambda1 = mid + torch.sqrt(max_values)\n",
    "    lambda2 = mid - torch.sqrt(max_values)\n",
    "    # now we have the eigenvalues, we can calculate the max radius\n",
    "    max_radius = torch.ceil(3.0 * torch.sqrt(torch.max(lambda1, lambda2)))\n",
    "\n",
    "    return max_radius\n",
    "\n",
    "\n",
    "inverted_covariance = compute_inverted_covariance(covariance_2d)\n",
    "extent = compute_extent_and_radius(covariance_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can now calculate the strength of any splat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The strength with a .1 pixel offset in the x direction is 0.9999192953109741\n",
      "The strength with a 1 pixel offset in the x direction is 0.4467449486255646\n",
      "The strength with a 10 pixel offset in the x direction is 1.0138366856677824e-35\n"
     ]
    }
   ],
   "source": [
    "from splat.utils import ndc2Pix\n",
    "\n",
    "splat = gaussians.points[in_view][:1]\n",
    "splat_2d_covariance = covariance_2d[:1]\n",
    "\n",
    "# project the splat to 2D\n",
    "homogeneous_splat = torch.cat(\n",
    "    [splat, torch.ones(splat.shape[0], 1, device=splat.device)], dim=1\n",
    ")\n",
    "temp_splat = homogeneous_splat @ extrinsic_matrix.T @ intrinsic_matrix\n",
    "splat_image_plane = temp_splat[:, :3] / temp_splat[:, 3].unsqueeze(1)\n",
    "splat_xy = splat_image_plane[:, :2]\n",
    "\n",
    "# convert to pixel coordinates from normalized device coordinates\n",
    "splat_xy[:, 0] = ndc2Pix(splat_xy[:, 0], width)\n",
    "splat_xy[:, 1] = ndc2Pix(splat_xy[:, 1], height)\n",
    "inverted_splat_2d_covariance = compute_inverted_covariance(splat_2d_covariance)\n",
    "radius = compute_extent_and_radius(splat_2d_covariance)\n",
    "\n",
    "\n",
    "def compute_gaussian_weight(\n",
    "    pixel_coord: torch.Tensor,  # (1, 2) tensor\n",
    "    point_mean: torch.Tensor,\n",
    "    inverse_covariance: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    difference = point_mean - pixel_coord\n",
    "    power = -0.5 * difference @ inverse_covariance @ difference.T\n",
    "    return torch.exp(power).item()\n",
    "\n",
    "\n",
    "strength = compute_gaussian_weight(\n",
    "    pixel_coord=splat_xy - 0.01,\n",
    "    point_mean=splat_xy,\n",
    "    inverse_covariance=inverted_splat_2d_covariance,\n",
    ")\n",
    "print(f\"The strength with a .1 pixel offset in the x direction is {strength}\")\n",
    "strength = compute_gaussian_weight(\n",
    "    pixel_coord=splat_xy - 1,\n",
    "    point_mean=splat_xy,\n",
    "    inverse_covariance=inverted_splat_2d_covariance,\n",
    ")\n",
    "print(f\"The strength with a 1 pixel offset in the x direction is {strength}\")\n",
    "strength = compute_gaussian_weight(\n",
    "    pixel_coord=splat_xy - 10,\n",
    "    point_mean=splat_xy,\n",
    "    inverse_covariance=inverted_splat_2d_covariance,\n",
    ")\n",
    "print(f\"The strength with a 10 pixel offset in the x direction is {strength}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we just need to render!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
