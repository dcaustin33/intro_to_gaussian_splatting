{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This will be a file to help determine if derviatives are correct that I derive by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from splat.utils import (\n",
    "    build_rotation,\n",
    "    get_extrinsic_matrix,\n",
    "    getIntrinsicMatrix,\n",
    "    read_camera_file,\n",
    "    read_image_file,\n",
    ")\n",
    "\n",
    "scales = torch.tensor([[-5, -5.5, -4.5, -5]])\n",
    "scales = torch.exp(scales)\n",
    "quaternions = torch.tensor([[0.2, 0.4, 0.3, 1.0]])\n",
    "point_3d = torch.tensor([[0.1, 0.1, -0.2]])\n",
    "color = torch.tensor([0.3, 0.4, 0.5])\n",
    "opacity = torch.tensor([0.5])\n",
    "\n",
    "\n",
    "focal_x = torch.tensor([100.0])\n",
    "focal_y = torch.tensor([100.0])\n",
    "c_x = torch.tensor([0.0])\n",
    "c_y = torch.tensor([0.0])\n",
    "width = torch.tensor([99.0])\n",
    "height = torch.tensor([99.0])\n",
    "camera_rotation = torch.tensor([1, 0, 0, 0]).unsqueeze(0)\n",
    "camera_translation = torch.tensor([[-0.1, -0.1, 0.0]])\n",
    "rotation_matrix = build_rotation(camera_rotation)\n",
    "extrinsic_matrix = get_extrinsic_matrix(rotation_matrix, camera_translation).T\n",
    "intrinsic_matrix = getIntrinsicMatrix(\n",
    "    focal_x=focal_x,\n",
    "    focal_y=focal_y,\n",
    "    width=width,\n",
    "    height=height,\n",
    "    zfar=100.0,\n",
    "    znear=0.01,\n",
    "    z_sign=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0202,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  2.0202,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  1.0001, -0.0200],\n",
      "        [ 0.0000,  0.0000,  1.0000,  0.0000]])\n",
      "tensor([[49.0000, 49.0000,  0.8000]])\n",
      "tensor([[[254503.1406,    408.5012,      0.0000],\n",
      "         [   408.5012, 252796.6562,      0.0000],\n",
      "         [     0.0000,      0.0000,      0.0000]]])\n",
      "tensor([[[ 3.9292e-06, -6.3494e-09,  0.0000e+00],\n",
      "         [-6.3494e-09,  3.9558e-06,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from splat.render_engine.utils import compute_fov_from_focal\n",
    "from splat.utils import ndc2Pix\n",
    "\n",
    "fovX = compute_fov_from_focal(focal_x, width)\n",
    "fovY = compute_fov_from_focal(focal_y, height)\n",
    "\n",
    "tan_fovX = math.tan(fovX / 2)\n",
    "tan_fovY = math.tan(fovY / 2)\n",
    "\n",
    "points_homogeneous = torch.cat(\n",
    "    [\n",
    "        point_3d,\n",
    "        torch.ones(point_3d.shape[0], 1),\n",
    "    ],\n",
    "    dim=1,\n",
    ")\n",
    "\n",
    "def get_3d_covariance_matrix(scales, quaternions):\n",
    "    quaternions = nn.functional.normalize(quaternions, p=2, dim=1)\n",
    "    # nx3x3 matrix\n",
    "    rotation_matrices = build_rotation(quaternions)\n",
    "    # nx3x3 matrix\n",
    "    scale_matrices = torch.zeros((len(point_3d), 3, 3))\n",
    "    scale = torch.exp(scales)\n",
    "    scale_matrices[:, 0, 0] = scale[:, 0]\n",
    "    scale_matrices[:, 1, 1] = scale[:, 1]\n",
    "    scale_matrices[:, 2, 2] = scale[:, 2]\n",
    "    m = rotation_matrices @ scale_matrices\n",
    "    covariance = m @ m.transpose(1, 2)\n",
    "    return covariance\n",
    "\n",
    "def invert_covariance_2d(covariance_2d: torch.Tensor, epsilon: float = 1e-6) -> torch.Tensor:\n",
    "    \"\"\"Covariance will ve a nX2X2 tensor\"\"\"\n",
    "    cov = covariance_2d + epsilon\n",
    "    determinant = cov[:, 0, 0] * cov[:, 1, 1] - cov[:, 0, 1] * cov[:, 1, 0]\n",
    "    inverted_cov = torch.zeros_like(cov).to(cov.device)\n",
    "    multiplier = 1.0 / determinant\n",
    "    inverted_cov[:, 0, 0] = cov[:, 1, 1] * multiplier\n",
    "    inverted_cov[:, 0, 1] = -cov[:, 0, 1] * multiplier\n",
    "    inverted_cov[:, 1, 0] = -cov[:, 1, 0] * multiplier\n",
    "    inverted_cov[:, 1, 1] = cov[:, 0, 0] * multiplier\n",
    "    return inverted_cov\n",
    "\n",
    "covariance_3d = get_3d_covariance_matrix(scales, quaternions)\n",
    "points_camera_space  = points_homogeneous @ extrinsic_matrix\n",
    "x = points_camera_space[:, 0] / points_camera_space[:, 2]\n",
    "y = points_camera_space[:, 1] / points_camera_space[:, 2]\n",
    "x = torch.clamp(x, -1.3 * tan_fovX, 1.3 * tan_fovX) * points_camera_space[:, 2]\n",
    "y = torch.clamp(y, -1.3 * tan_fovY, 1.3 * tan_fovY) * points_camera_space[:, 2]\n",
    "z = points_camera_space[:, 2]\n",
    "j = torch.zeros((points_camera_space.shape[0], 3, 3))\n",
    "j[:, 0, 0] = focal_x / z\n",
    "j[:, 0, 2] = -(focal_x * x) / (z ** 2)\n",
    "j[:, 1, 1] = focal_y / z\n",
    "j[:, 1, 2] = -(focal_y * y) / (z ** 2)\n",
    "\n",
    "w = extrinsic_matrix[:3, :3]\n",
    "t = w @ j.transpose(1, 2)\n",
    "covariance2d = (\n",
    "    t.transpose(1, 2)\n",
    "    @ covariance_3d.transpose(1, 2) # doesnt this not do anything?\n",
    "    @ t\n",
    ")\n",
    "# scale by 0.3 for the covariance and numerical stability on the diagonal\n",
    "# this is a hack to make the covariance matrix more stable\n",
    "# this is a hack to make the covariance matrix more stable\n",
    "covariance2d[:, 0, 0] = covariance2d[:, 0, 0] + 0.3\n",
    "covariance2d[:, 1, 1] = covariance2d[:, 1, 1] + 0.3\n",
    "\n",
    "inverted_covariance_2d = invert_covariance_2d(covariance2d)\n",
    "\n",
    "print(intrinsic_matrix)\n",
    "points_ndc = points_camera_space @ intrinsic_matrix\n",
    "points_ndc[:, :2] = points_ndc[:, :2] / points_ndc[:, 3].unsqueeze(1) \n",
    "points_ndc = points_ndc[:, :3]  # nx3\n",
    "pixel_coords_x = ndc2Pix(points_ndc[:, 0], dimension=width)\n",
    "pixel_coords_y = ndc2Pix(points_ndc[:, 1], dimension=height)\n",
    "points_ndc[:, 0] = pixel_coords_x\n",
    "points_ndc[:, 1] = pixel_coords_y\n",
    "print(points_ndc)\n",
    "print(covariance2d)\n",
    "print(inverted_covariance_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(-0.8133, grad_fn=<SubBackward0>)\n",
      "Gradient:  tensor([[2.2000e-06, 7.3512e-07]])\n",
      "output_ndc gradient:  tensor([[[2.2000e-06],\n",
      "         [7.3512e-07]],\n",
      "\n",
      "        [[2.2000e-06],\n",
      "         [7.3512e-07]]])\n"
     ]
    }
   ],
   "source": [
    "def extract_gaussian_weight(\n",
    "    pixel: torch.Tensor, mean: torch.Tensor, inv_covariance: torch.Tensor, pdb: bool = False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Use the covariance matrix to extract the weight of the point\n",
    "\n",
    "    Args:\n",
    "        mean: 1x2 tensor\n",
    "        covariance: 2x2 tensor\n",
    "    \"\"\"\n",
    "    diff = pixel - mean\n",
    "    diff = diff.unsqueeze(0)\n",
    "    gaussian_weight = -0.5 * torch.matmul(diff, torch.matmul(inv_covariance, diff.t()))\n",
    "    actual_weight = torch.exp(gaussian_weight)\n",
    "    return actual_weight, gaussian_weight\n",
    "\n",
    "def render_pixel(\n",
    "    x_value: int,\n",
    "    y_value: int,\n",
    "    mean_2d: torch.Tensor,\n",
    "    inv_covariance_2d: torch.Tensor,\n",
    "    opacity: torch.Tensor,\n",
    "    color: torch.Tensor,\n",
    "    current_T: float,\n",
    "    min_weight: float = 0.00001,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    \"\"\"Uses alpha blending to render a pixel\"\"\"\n",
    "    gaussian_strength, exponent_weight = extract_gaussian_weight(\n",
    "        torch.Tensor([x_value, y_value]), mean_2d, inv_covariance_2d\n",
    "    )\n",
    "    alpha = gaussian_strength * torch.sigmoid(opacity)\n",
    "    test_t = current_T * (1 - alpha)\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"x_value: {x_value}, y_value: {y_value}, gaussian_strength: {gaussian_strength}, alpha: {alpha}, test_t: {test_t}, mean_2d: {mean_2d}\"\n",
    "        )\n",
    "    if test_t < min_weight:\n",
    "        return\n",
    "    return color * current_T * alpha, test_t, current_T, gaussian_strength, exponent_weight\n",
    "\n",
    "def compute_gradient_wrt_ndc(\n",
    "    current_T: float,\n",
    "    color: torch.Tensor,\n",
    "    opacity: torch.Tensor,\n",
    "    gaussian_weight: torch.Tensor,\n",
    "    exponent_weight: torch.Tensor,\n",
    "    inverted_covariance_2d: torch.Tensor,\n",
    "    diff_x: torch.Tensor,\n",
    "    diff_y: torch.Tensor,\n",
    "):\n",
    "    difference = torch.cat([diff_x, diff_y], dim=1)\n",
    "    grad = current_T * color * torch.sigmoid(opacity) * torch.exp(exponent_weight)\n",
    "    grad = grad * -0.5 * (inverted_covariance_2d + inverted_covariance_2d.transpose(1, 2)) @ difference.view(-1, 2, 1) * -1\n",
    "    return grad\n",
    "\n",
    "point_mean = torch.tensor([[47.0, 49.0]]).requires_grad_(True)\n",
    "# inverted_covariance_2d = torch.tensor([[1.0, 0.0, 0.0, 1.0]]).view(1, 2, 2)\n",
    "opacity = torch.tensor([0.5])\n",
    "color = torch.tensor([0.3, 0.4, 0.5])\n",
    "pixel_coords = torch.tensor([[50.0, 50.0]])\n",
    "\n",
    "output, test_t, current_T, gaussian_strength, exponent_weight = render_pixel(\n",
    "    pixel_coords[0, 0], \n",
    "    pixel_coords[0, 1], \n",
    "    point_mean[0, :2], \n",
    "    inverted_covariance_2d[:, :2, :2], \n",
    "    opacity, \n",
    "    color, \n",
    "    1.0\n",
    ")\n",
    "\n",
    "loss = output[0, 0, 0] - 1.0\n",
    "print(\"Loss: \", loss)\n",
    "loss.backward()\n",
    "print(\"Gradient: \", point_mean.grad)\n",
    "\n",
    "output_ndc = compute_gradient_wrt_ndc(\n",
    "    current_T=torch.Tensor([[1.0], [1.0]]),\n",
    "    color=torch.Tensor([[color[0]], [color[0]]]),\n",
    "    opacity=torch.Tensor([[opacity], [opacity]]),\n",
    "    gaussian_weight=torch.Tensor([[gaussian_strength], [gaussian_strength]]),\n",
    "    exponent_weight=torch.Tensor([[exponent_weight], [exponent_weight]]),\n",
    "    inverted_covariance_2d=torch.stack([inverted_covariance_2d[:, :2, :2], inverted_covariance_2d[:, :2, :2]]).view(-1, 2, 2),\n",
    "    diff_x=torch.Tensor([[pixel_coords[0, 0] - point_mean[0, 0]], [pixel_coords[0, 0] - point_mean[0, 0]]]),\n",
    "    diff_y=torch.Tensor([[pixel_coords[0, 1] - point_mean[0, 1]], [pixel_coords[0, 1] - point_mean[0, 1]]]),\n",
    ")\n",
    "print(\"output_ndc gradient: \", output_ndc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2474, -2.7526]], grad_fn=<SubBackward0>)\n",
      "Loss:  tensor(9.1328, grad_fn=<SumBackward0>)\n",
      "Gradient:  tensor([[ 6.1735e+04, -1.3623e+05, -3.7240e+00]])\n",
      "two_by_4_jacobian:  tensor([[[ 2.4745e+04,  0.0000e+00,  1.2371e+00, -2.4745e+03],\n",
      "         [ 0.0000e+00,  2.4745e+04,  1.2371e+00, -2.4745e+03]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "final_point_ndc:  tensor([[49.2474, 49.2474]], grad_fn=<ViewBackward0>)\n",
      "ground_truth_ndc:  tensor([[48., 52.]])\n",
      "derivative_l2_wrt_pndc:  tensor([[[ 2.4948, -5.5052]]], grad_fn=<CopySlices>)\n",
      "Computed Gradient:  tensor([[[ 6.1735e+04, -1.3623e+05, -3.7240e+00]]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def ndc2Pix(points: torch.Tensor, dimension: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert points from NDC to pixel coordinates\n",
    "    \"\"\"\n",
    "    return (points + 1) * (dimension - 1) * 0.5\n",
    "\n",
    "def compute_ndc_gradient(\n",
    "    intrinsic_matrix: torch.Tensor,\n",
    "    extrinsic_matrix: torch.Tensor,\n",
    "    point_ndc_1: torch.Tensor,\n",
    "    final_point_ndc: torch.Tensor,\n",
    "    ground_truth_ndc: torch.Tensor,\n",
    "    width: torch.Tensor,\n",
    "    height: torch.Tensor,\n",
    "):\n",
    "    pixel_gradient = torch.tensor([[(width - 1) / 2, 0], [0, (height - 1) / 2]])\n",
    "    jacobian_pndc_1 = torch.zeros((point_ndc_1.shape[0], 2, 4))\n",
    "    jacobian_pndc_1[:, 0, 0] = 1/point_ndc_1[:, 3]\n",
    "    jacobian_pndc_1[:, 1, 1] = 1/point_ndc_1[:, 3]\n",
    "    jacobian_pndc_1[:, 0, 3] = -point_ndc_1[:, 0] / point_ndc_1[:, 3]**2\n",
    "    jacobian_pndc_1[:, 1, 3] = -point_ndc_1[:, 1] / point_ndc_1[:, 3]**2\n",
    "    two_by_4_jacobian = pixel_gradient @ jacobian_pndc_1 @ intrinsic_matrix.T @ extrinsic_matrix.T\n",
    "    print(\"two_by_4_jacobian: \", two_by_4_jacobian)\n",
    "    derivative_l2_wrt_pndc = torch.zeros((point_ndc_1.shape[0], 1, 2))\n",
    "    print(\"final_point_ndc: \", final_point_ndc)\n",
    "    print(\"ground_truth_ndc: \", ground_truth_ndc)\n",
    "    derivative_l2_wrt_pndc[:, :, 0] = (final_point_ndc[:, :1] - ground_truth_ndc[:, :1]) * 2\n",
    "    derivative_l2_wrt_pndc[:, :, 1] = (final_point_ndc[:, 1:2] - ground_truth_ndc[:, 1:2]) * 2\n",
    "    print(\"derivative_l2_wrt_pndc: \", derivative_l2_wrt_pndc)\n",
    "    final_grad = derivative_l2_wrt_pndc @ two_by_4_jacobian\n",
    "    return final_grad[:, :, :3]\n",
    "\n",
    "point_3d = torch.tensor([[0.10001, 0.10001, -0.2]]).requires_grad_(True)\n",
    "homogeneous_point = torch.cat([point_3d, torch.ones(point_3d.shape[0], 1)], dim=1)\n",
    "point_camera_space = homogeneous_point @ extrinsic_matrix\n",
    "point_ndc_1 = point_camera_space @ intrinsic_matrix\n",
    "\n",
    "point_ndc = point_ndc_1[:, :2] / point_ndc_1[:, 3].unsqueeze(1)\n",
    "pixel_space_x = ndc2Pix(point_ndc[:, 0], width)\n",
    "pixel_space_y = ndc2Pix(point_ndc[:, 1], height)\n",
    "final_point_ndc = torch.cat([pixel_space_x, pixel_space_y]).view(-1, 2)\n",
    "ground_truth_ndc = torch.tensor([[48.0, 52.0]])\n",
    "\n",
    "print(final_point_ndc - ground_truth_ndc)\n",
    "loss = (final_point_ndc - ground_truth_ndc).pow(2).sum()\n",
    "print(\"Loss: \", loss)\n",
    "loss.backward()\n",
    "print(\"Gradient: \", point_3d.grad)\n",
    "\n",
    "computed_gradient = compute_ndc_gradient(\n",
    "    intrinsic_matrix=intrinsic_matrix,\n",
    "    extrinsic_matrix=extrinsic_matrix,\n",
    "    point_ndc_1=point_ndc_1,\n",
    "    final_point_ndc=final_point_ndc,\n",
    "    ground_truth_ndc=ground_truth_ndc,\n",
    "    width=width,\n",
    "    height=height,\n",
    ")\n",
    "print(\"Computed Gradient: \", computed_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(17.2759, grad_fn=<SumBackward0>)\n",
      "Gradient:  tensor([[ 6.1735e+04, -1.3623e+05, -3.7240e+00],\n",
      "        [ 3.7245e+04, -1.3623e+05, -8.6724e+00]])\n",
      "two_by_4_jacobian:  torch.Size([2, 2, 4])\n",
      "derivative_l2_wrt_pndc:  torch.Size([2, 1, 2])\n",
      "Computed Gradient:  tensor([[[ 6.1735e+04, -1.3623e+05, -3.7240e+00]],\n",
      "\n",
      "        [[ 3.7245e+04, -1.3623e+05, -8.6724e+00]]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def ndc2Pix(points: torch.Tensor, dimension: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert points from NDC to pixel coordinates\n",
    "    \"\"\"\n",
    "    return (points + 1) * (dimension - 1) * 0.5\n",
    "\n",
    "def compute_ndc_gradient(\n",
    "    intrinsic_matrix: torch.Tensor,\n",
    "    extrinsic_matrix: torch.Tensor,\n",
    "    point_ndc_1: torch.Tensor,\n",
    "    final_point_ndc: torch.Tensor,\n",
    "    ground_truth_ndc: torch.Tensor,\n",
    "    width: torch.Tensor,\n",
    "    height: torch.Tensor,\n",
    "):\n",
    "    pixel_gradient = torch.tensor([[(width - 1) / 2, 0], [0, (height - 1) / 2]])\n",
    "    jacobian_pndc_1 = torch.zeros((point_ndc_1.shape[0], 2, 4))\n",
    "    jacobian_pndc_1[:, 0, 0] = 1/point_ndc_1[:, 3]\n",
    "    jacobian_pndc_1[:, 1, 1] = 1/point_ndc_1[:, 3]\n",
    "    jacobian_pndc_1[:, 0, 3] = -point_ndc_1[:, 0] / point_ndc_1[:, 3]**2\n",
    "    jacobian_pndc_1[:, 1, 3] = -point_ndc_1[:, 1] / point_ndc_1[:, 3]**2\n",
    "    two_by_4_jacobian = pixel_gradient @ jacobian_pndc_1 @ intrinsic_matrix.T @ extrinsic_matrix.T\n",
    "    derivative_l2_wrt_pndc = torch.zeros((point_ndc_1.shape[0], 1, 2))\n",
    "    derivative_l2_wrt_pndc[:, :, 0] = (final_point_ndc[:, :1] - ground_truth_ndc[:, :1]) * 2\n",
    "    derivative_l2_wrt_pndc[:, :, 1] = (final_point_ndc[:, 1:2] - ground_truth_ndc[:, 1:2]) * 2\n",
    "    print(\"two_by_4_jacobian: \", two_by_4_jacobian.shape)\n",
    "    print(\"derivative_l2_wrt_pndc: \", derivative_l2_wrt_pndc.shape)\n",
    "    final_grad = derivative_l2_wrt_pndc @ two_by_4_jacobian\n",
    "    return final_grad[:, :, :3]\n",
    "\n",
    "point_3d = torch.tensor([[0.10001, 0.10001, -0.2], [0.09999, 0.10001, -0.2]]).view(-1, 3).requires_grad_(True)\n",
    "homogeneous_point = torch.cat([point_3d, torch.ones(point_3d.shape[0], 1)], dim=1)\n",
    "point_camera_space = homogeneous_point @ extrinsic_matrix\n",
    "point_ndc_1 = point_camera_space @ intrinsic_matrix\n",
    "\n",
    "point_ndc = point_ndc_1[:, :2] / point_ndc_1[:, 3].unsqueeze(1)\n",
    "pixel_space_x = ndc2Pix(point_ndc[:, 0], width)\n",
    "pixel_space_y = ndc2Pix(point_ndc[:, 1], height)\n",
    "final_point_ndc = torch.cat([pixel_space_x.view(-1, 1), pixel_space_y.view(-1, 1)], dim=1)\n",
    "ground_truth_ndc = torch.tensor([[48.0, 52.0], [48.0, 52.0]])\n",
    "\n",
    "loss = (final_point_ndc - ground_truth_ndc).pow(2).sum()\n",
    "print(\"Loss: \", loss)\n",
    "loss.backward()\n",
    "print(\"Gradient: \", point_3d.grad)\n",
    "\n",
    "computed_gradient = compute_ndc_gradient(\n",
    "    intrinsic_matrix=intrinsic_matrix,\n",
    "    extrinsic_matrix=extrinsic_matrix,\n",
    "    point_ndc_1=point_ndc_1,\n",
    "    final_point_ndc=final_point_ndc,\n",
    "    ground_truth_ndc=ground_truth_ndc,\n",
    "    width=width,\n",
    "    height=height,\n",
    ")\n",
    "print(\"Computed Gradient: \", computed_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coords:  tensor([[49.2474, 49.2474],\n",
      "        [48.7526, 49.2474]], grad_fn=<pixelSpaceToPixelsBackward>)\n",
      "Loss:  tensor(17.2759, grad_fn=<SumBackward0>)\n",
      "Gradient:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "from splat.test.partials import pixelSpaceToPixels\n",
    "\n",
    "point_3d = torch.tensor([[0.10001, 0.10001, -0.2], [0.09999, 0.10001, -0.2]]).view(-1, 3).requires_grad_(True)\n",
    "ground_truth_ndc = torch.tensor([[48.0, 52.0], [48.0, 52.0]])\n",
    "coords = pixelSpaceToPixels.apply(point_3d, width, height, intrinsic_matrix, extrinsic_matrix)\n",
    "print(\"Coords: \", coords)\n",
    "loss = (coords - ground_truth_ndc).pow(2).sum()\n",
    "print(\"Loss: \", loss)\n",
    "loss.backward()\n",
    "print(\"Gradient: \", point_3d.grad.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  tensor([[[0.1867, 0.2490, 0.3112]]], grad_fn=<MulBackward0>)\n",
      "Loss:  tensor(0.0075, grad_fn=<SumBackward0>)\n",
      "Gradient:  tensor([[8.9794e-07, 3.0004e-07]])\n",
      "Loss:  tensor(0.0075, grad_fn=<SumBackward0>)\n",
      "Gradient:  tensor([[8.9794e-07, 3.0004e-07]])\n",
      "Autograd Output:  tensor([[[0.1867, 0.2490, 0.3112]]], grad_fn=<pixelCoordToColorBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from splat.test.partials import (\n",
    "    d_color_wrt_alpha,\n",
    "    d_alpha_wrt_gaussian_strength,\n",
    "    d_gaussian_strength_wrt_gaussian_weight,\n",
    "    d_gaussian_weight_wrt_diff,\n",
    "    d_diff_wrt_mean,\n",
    ")\n",
    "\n",
    "\n",
    "def extract_gaussian_weight(\n",
    "    pixel: torch.Tensor, mean: torch.Tensor, inv_covariance: torch.Tensor, pdb: bool = False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Use the covariance matrix to extract the weight of the point\n",
    "\n",
    "    Args:\n",
    "        mean: 1x2 tensor\n",
    "        covariance: 2x2 tensor\n",
    "    \"\"\"\n",
    "    diff = pixel - mean\n",
    "    diff = diff.unsqueeze(0)\n",
    "    gaussian_weight = -0.5 * torch.matmul(diff, torch.matmul(inv_covariance, diff.t()))\n",
    "    actual_weight = torch.exp(gaussian_weight)\n",
    "    return actual_weight, gaussian_weight\n",
    "\n",
    "def render_pixel(\n",
    "    x_value: int,\n",
    "    y_value: int,\n",
    "    mean_2d: torch.Tensor,\n",
    "    inv_covariance_2d: torch.Tensor,\n",
    "    opacity: torch.Tensor,\n",
    "    color: torch.Tensor,\n",
    "    current_T: float,\n",
    "    min_weight: float = 0.00001,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    \"\"\"Uses alpha blending to render a pixel\"\"\"\n",
    "    gaussian_strength, exponent_weight = extract_gaussian_weight(\n",
    "        torch.Tensor([x_value, y_value]), mean_2d, inv_covariance_2d\n",
    "    )\n",
    "    alpha = gaussian_strength * torch.sigmoid(opacity)\n",
    "    test_t = current_T * (1 - alpha)\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"x_value: {x_value}, y_value: {y_value}, gaussian_strength: {gaussian_strength}, alpha: {alpha}, test_t: {test_t}, mean_2d: {mean_2d}\"\n",
    "        )\n",
    "    if test_t < min_weight:\n",
    "        return\n",
    "    return color * current_T * alpha, test_t, current_T, gaussian_strength, exponent_weight\n",
    "\n",
    "\n",
    "class pixelCoordToColor(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(\n",
    "        ctx, \n",
    "        pixel_coords: torch.Tensor, \n",
    "        gaussian_coords: torch.Tensor, \n",
    "        color: torch.Tensor, \n",
    "        inv_covariance_2d: torch.Tensor,\n",
    "        current_T: torch.Tensor,\n",
    "        opacity: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        pixel_coords: nx2 tensor\n",
    "        gaussian_coords: nx2 tensor\n",
    "        color: nx3 tensor\n",
    "        inv_covariance_2d: nx2x2 tensor\n",
    "        current_T: nx1 tensor   \n",
    "        opacity: nx1 tensor\n",
    "        \"\"\"\n",
    "        diff = pixel_coords - gaussian_coords\n",
    "        diff = diff.unsqueeze(0)\n",
    "        gaussian_weight = -0.5 * torch.matmul(diff, torch.matmul(inv_covariance_2d, diff.transpose(1, 2)))\n",
    "        actual_weight = torch.exp(gaussian_weight)\n",
    "        alpha = actual_weight * torch.sigmoid(opacity)\n",
    "        ctx.save_for_backward(pixel_coords, gaussian_coords, color, inv_covariance_2d, current_T, opacity, gaussian_weight, diff)\n",
    "        return color * current_T * alpha\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: torch.Tensor) -> torch.Tensor:\n",
    "        pixel_coords, gaussian_coords, color, inv_covariance_2d, current_T, opacity, gaussian_weight, diff = ctx.saved_tensors\n",
    "        derivative = d_color_wrt_alpha(color, current_T).view(-1, 3, 1)\n",
    "        derivative = derivative * d_alpha_wrt_gaussian_strength(opacity)\n",
    "        derivative = derivative * d_gaussian_strength_wrt_gaussian_weight(gaussian_weight)\n",
    "        derivative = torch.bmm(derivative, d_gaussian_weight_wrt_diff(diff, inv_covariance_2d).transpose(1, 2))\n",
    "        derivative = torch.bmm(derivative, d_diff_wrt_mean(diff.shape[0]))\n",
    "        deriviative = torch.bmm(grad_output, derivative)\n",
    "        return None, None, None, None, None, None\n",
    "    \n",
    "    \n",
    "point_mean = torch.tensor([[47.0, 49.0]]).requires_grad_(True)\n",
    "# inverted_covariance_2d = torch.tensor([[1.0, 0.0, 0.0, 1.0]]).view(1, 2, 2)\n",
    "opacity = torch.tensor([0.5]).view(-1, 1)\n",
    "color = torch.tensor([[0.3, 0.4, 0.5]]).view(-1, 3)\n",
    "pixel_coords = torch.tensor([[50.0, 50.0]]).view(-1, 2)\n",
    "\n",
    "output, test_t, current_T, gaussian_strength, exponent_weight = render_pixel(\n",
    "    pixel_coords[0, 0], \n",
    "    pixel_coords[0, 1], \n",
    "    point_mean[0, :2], \n",
    "    inverted_covariance_2d[:, :2, :2], \n",
    "    opacity, \n",
    "    color, \n",
    "    1.0\n",
    ")\n",
    "print(\"Output: \", output)\n",
    "expected = torch.tensor([[0.15, 0.2, 0.25]])\n",
    "loss = (output - expected).pow(2).sum()\n",
    "print(\"Loss: \", loss)\n",
    "loss.backward()\n",
    "print(\"Gradient: \", point_mean.grad)\n",
    "\n",
    "output = pixelCoordToColor.apply(pixel_coords, point_mean, color, inverted_covariance_2d[:, :2, :2], torch.tensor([1.0]), opacity)\n",
    "loss = (output - expected).pow(2).sum()\n",
    "print(\"Loss: \", loss)\n",
    "loss.backward()\n",
    "print(\"Gradient: \", point_mean.grad)\n",
    "print(\"Autograd Output: \", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opacity:  tensor([[0.5000]])\n",
      "Color:  tensor([[0.3000, 0.4000, 0.5000]])\n",
      "Final Output:  torch.Size([2, 3])\n",
      "Expected:  tensor([[0.1500, 0.2000, 0.2500],\n",
      "        [0.1500, 0.2000, 0.2500]])\n",
      "final_output - expected:  tensor([[0.0367, 0.0490, 0.0612],\n",
      "        [0.0367, 0.0490, 0.0612]], grad_fn=<SubBackward0>)\n",
      "Loss:  tensor(0.0150, grad_fn=<SumBackward0>)\n",
      "Gradient:  tensor([[ 5.5686e-03,  5.6062e-03,  5.5867e-07],\n",
      "        [ 9.2358e-03,  5.6002e-03, -1.8176e-07]])\n"
     ]
    }
   ],
   "source": [
    "point_3d = torch.tensor([[0.10001, 0.10001, -0.2], [0.09999, 0.10001, -0.2]]).requires_grad_(True)\n",
    "opacity = torch.tensor([0.5, 0.5]).view(-1, 1)\n",
    "color = torch.tensor([[0.3, 0.4, 0.5], [0.3, 0.4, 0.5]]).view(-1, 3)\n",
    "pixel_coord = torch.Tensor([[50.0, 50.0], [50.0, 50.0]]).view(-1, 2)\n",
    "expected = torch.tensor([[0.15, 0.2, 0.25], [0.15, 0.2, 0.25]])\n",
    "\n",
    "homogeneous_point = torch.cat([point_3d, torch.ones(point_3d.shape[0], 1)], dim=1)\n",
    "point_camera_space = homogeneous_point @ extrinsic_matrix\n",
    "point_ndc_1 = point_camera_space @ intrinsic_matrix\n",
    "\n",
    "point_ndc = point_ndc_1[:, :2] / point_ndc_1[:, 3].unsqueeze(1)\n",
    "pixel_space_x = ndc2Pix(point_ndc[:, 0], width)\n",
    "pixel_space_y = ndc2Pix(point_ndc[:, 1], height)\n",
    "final_point_ndc = torch.cat([pixel_space_x.view(-1, 1), pixel_space_y.view(-1, 1)], dim=1)\n",
    "\n",
    "output, test_t, current_T, gaussian_strength, exponent_weight = render_pixel(\n",
    "    pixel_coord[0, 0], \n",
    "    pixel_coord[0, 1], \n",
    "    final_point_ndc[0, :2], \n",
    "    inverted_covariance_2d[0:1, :2, :2], \n",
    "    opacity[0:1], \n",
    "    color[0:1], \n",
    "    1.0\n",
    ")\n",
    "\n",
    "print(\"Opacity: \", opacity[1:2])\n",
    "print(\"Color: \", color[1:2])\n",
    "output2, test_t2, current_T2, gaussian_strength2, exponent_weight2 = render_pixel(\n",
    "    pixel_coord[1, 0], \n",
    "    pixel_coord[1, 1], \n",
    "    final_point_ndc[1, :2], \n",
    "    inverted_covariance_2d[0:1, :2, :2], \n",
    "    opacity[1:2], \n",
    "    color[1:2], \n",
    "    1.0\n",
    ")\n",
    "\n",
    "final_output = torch.cat([output, output2], dim=0).squeeze(1)\n",
    "print(\"Final Output: \", final_output.shape)\n",
    "print(\"Expected: \", expected)\n",
    "print(\"final_output - expected: \", final_output - expected)\n",
    "loss = (final_output - expected).pow(2).sum()\n",
    "print(\"Loss: \", loss)\n",
    "loss.backward()\n",
    "print(\"Gradient: \", point_3d.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  tensor([[0.1867, 0.2490, 0.3112],\n",
      "        [0.1867, 0.2490, 0.3112]], grad_fn=<pixelCoordToColorBackward>)\n",
      "Expected:  tensor([[0.1500, 0.2000, 0.2500],\n",
      "        [0.1500, 0.2000, 0.2500]])\n",
      "output - expected:  tensor([[0.0367, 0.0490, 0.0612],\n",
      "        [0.0367, 0.0490, 0.0612]], grad_fn=<SubBackward0>)\n",
      "Loss:  tensor(0.0150, grad_fn=<SumBackward0>)\n",
      "Gradient:  tensor([[ 5.5686e-03,  5.6062e-03,  5.5867e-07],\n",
      "        [ 9.2358e-03,  5.6002e-03, -1.8176e-07]])\n",
      "Autograd Output:  tensor([[0.1867, 0.2490, 0.3112],\n",
      "        [0.1867, 0.2490, 0.3112]], grad_fn=<pixelCoordToColorBackward>)\n"
     ]
    }
   ],
   "source": [
    "from splat.test.partials import pixelCoordToColor, pixelSpaceToPixels\n",
    "\n",
    "point_3d = torch.tensor([[0.10001, 0.10001, -0.2], [0.09999, 0.10001, -0.2]]).requires_grad_(True)\n",
    "opacity = torch.tensor([0.5, 0.5]).view(-1, 1)\n",
    "color = torch.tensor([[0.3, 0.4, 0.5], [0.3, 0.4, 0.5]]).view(-1, 3)\n",
    "pixel_coord = torch.Tensor([[50.0, 50.0], [50.0, 50.0]]).view(-1, 2)\n",
    "expected = torch.tensor([[0.15, 0.2, 0.25], [0.15, 0.2, 0.25]])\n",
    "inverted_covariance_2d = inverted_covariance_2d.repeat(2, 1, 1)[:, :2, :2]\n",
    "\n",
    "pixel_space = pixelSpaceToPixels.apply(point_3d, width, height, intrinsic_matrix, extrinsic_matrix)\n",
    "output = pixelCoordToColor.apply(pixel_coord, pixel_space, color, inverted_covariance_2d[:, :2, :2], torch.tensor([1.0]), opacity)\n",
    "\n",
    "loss = (output - expected).pow(2).sum()\n",
    "print(\"Output: \", output)\n",
    "print(\"Expected: \", expected)\n",
    "print(\"output - expected: \", output - expected)\n",
    "print(\"Loss: \", loss)\n",
    "loss.backward()\n",
    "print(\"Gradient: \", point_3d.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.9292e-06, -6.3494e-09],\n",
       "         [-6.3494e-09,  3.9558e-06]],\n",
       "\n",
       "        [[ 3.9292e-06, -6.3494e-09],\n",
       "         [-6.3494e-09,  3.9558e-06]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_covariance_2d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
