{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splat.gaussians import Gaussians\n",
    "from splat.gaussian_scene import GaussianScene\n",
    "import pycolmap\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from splat.utils import read_images_text, read_images_binary\n",
    "\n",
    "colmap_path = \"treehill/sparse/0\"\n",
    "reconstruction = pycolmap.Reconstruction(colmap_path)\n",
    "\n",
    "points3d = reconstruction.points3D\n",
    "images = read_images_binary(f\"{colmap_path}/images.bin\")\n",
    "cameras = reconstruction.cameras\n",
    "\n",
    "all_points3d = []\n",
    "all_point_colors = []\n",
    "\n",
    "for idx, point in enumerate(points3d.values()):\n",
    "    if point.track.length() >= 2:\n",
    "        all_points3d.append(point.xyz)\n",
    "        all_point_colors.append(point.color)\n",
    "\n",
    "gaussians = Gaussians(\n",
    "    torch.Tensor(all_points3d), \n",
    "    torch.Tensor(all_point_colors),\n",
    "    model_path=\"point_clouds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert 3d gaussians to 2d\n",
    "Note: we are only using isotropic gaussians for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from splat.utils import read_camera_file, read_image_file, build_rotation, in_view_frustum\n",
    "\n",
    "\n",
    "def get_extrinsic_matrix(R: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Get the homogenous extrinsic matrix for the camera\n",
    "    \"\"\"\n",
    "    Rt = torch.zeros((4, 4))\n",
    "    Rt[:3, :3] = R\n",
    "    Rt[:3, 3] = t\n",
    "    Rt[3, 3] = 1.0\n",
    "    return Rt\n",
    "\n",
    "\n",
    "def getIntinsicMatrix(\n",
    "    focal_x: torch.Tensor,\n",
    "    focal_y: torch.Tensor,\n",
    "    height: torch.Tensor,\n",
    "    width: torch.Tensor,\n",
    "    znear: torch.Tensor = torch.Tensor([100.0]),\n",
    "    zfar: torch.Tensor = torch.Tensor([0.001]),\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Gets the internal perspective projection matrix\n",
    "    \n",
    "    znear: near plane set by user\n",
    "    zfar: far plane set by user\n",
    "    fovX: field of view in x, calculated from the focal length\n",
    "    fovY: field of view in y, calculated from the focal length\n",
    "    \"\"\"\n",
    "    fovX = torch.Tensor([2 * math.atan(width / (2 * focal_x))])\n",
    "    fovY = torch.Tensor([2 * math.atan(height / (2 * focal_y))])\n",
    "    \n",
    "    tanHalfFovY = math.tan((fovY / 2))\n",
    "    tanHalfFovX = math.tan((fovX / 2))\n",
    "\n",
    "    top = tanHalfFovY * znear\n",
    "    bottom = -top\n",
    "    right = tanHalfFovX * znear\n",
    "    left = -right\n",
    "\n",
    "    P = torch.zeros(4, 4)\n",
    "\n",
    "    z_sign = 1.0\n",
    "\n",
    "    P[0, 0] = 2.0 * znear / (right - left)\n",
    "    P[1, 1] = 2.0 * znear / (top - bottom)\n",
    "    P[0, 2] = (right + left) / (right - left)\n",
    "    P[1, 2] = (top + bottom) / (top - bottom)\n",
    "    P[3, 2] = z_sign\n",
    "    P[2, 2] = z_sign * zfar / (zfar - znear)\n",
    "    P[2, 3] = -(zfar * znear) / (zfar - znear)\n",
    "    return P\n",
    "\n",
    "\n",
    "def compute_2d_covariance(\n",
    "    points: torch.Tensor,\n",
    "    extrinsic_matrix: torch.Tensor,\n",
    "    covariance_3d: torch.Tensor,\n",
    "    tan_fovY: torch.Tensor,\n",
    "    tan_fovX: torch.Tensor,\n",
    "    focal_x: torch.Tensor,\n",
    "    focal_y: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the 2D covariance matrix for each gaussian\n",
    "    \"\"\"\n",
    "    points = torch.cat(\n",
    "        [points, torch.ones(points.shape[0], 1, device=points.device)], dim=1\n",
    "    )\n",
    "    points_transformed = (points @ extrinsic_matrix)[:, :3]\n",
    "    limx = 1.3 * tan_fovX\n",
    "    limy = 1.3 * tan_fovY\n",
    "    x = points_transformed[:, 0] / points_transformed[:, 2]\n",
    "    y = points_transformed[:, 1] / points_transformed[:, 2]\n",
    "    z = points_transformed[:, 2]\n",
    "    x = torch.clamp(x, -limx, limx) * z\n",
    "    y = torch.clamp(y, -limy, limy) * z\n",
    "\n",
    "    J = torch.zeros((points_transformed.shape[0], 3, 3), device=covariance_3d.device)\n",
    "    J[:, 0, 0] = focal_x / z\n",
    "    J[:, 0, 2] = -(focal_x * x) / (z**2)\n",
    "    J[:, 1, 1] = focal_y / z\n",
    "    J[:, 1, 2] = -(focal_y * y) / (z**2)\n",
    "\n",
    "    # transpose as originally set up for perspective projection\n",
    "    # so we now transform back\n",
    "    W = extrinsic_matrix[:3, :3].T\n",
    "\n",
    "    return (J @ W @ covariance_3d @ W.T @ J.transpose(1, 2))[:, :2, :2]\n",
    "\n",
    "covariance_3d = gaussians.get_3d_covariance_matrix()\n",
    "\n",
    "# we will examine the 100th image\n",
    "image_num = 100    \n",
    "image_dict = read_image_file(colmap_path)\n",
    "camera_dict = read_camera_file(colmap_path)\n",
    "\n",
    "# convert quaternion to rotation matrix\n",
    "rotation_matrix = build_rotation(torch.Tensor(image_dict[image_num].qvec).unsqueeze(0))\n",
    "translation = torch.Tensor(image_dict[image_num].tvec).unsqueeze(0)\n",
    "extrinsic_matrix = get_extrinsic_matrix(\n",
    "    rotation_matrix, translation\n",
    ")\n",
    "focal_x, focal_y = camera_dict[image_dict[image_num].camera_id].params[:2]\n",
    "c_x, c_y = camera_dict[image_dict[image_num].camera_id].params[2:4]\n",
    "width = camera_dict[image_dict[image_num].camera_id].width\n",
    "height = camera_dict[image_dict[image_num].camera_id].height\n",
    "intrinsic_matrix = getIntinsicMatrix(\n",
    "    focal_x, focal_y, height, width\n",
    ")\n",
    "in_view = in_view_frustum(\n",
    "    points=gaussians.points,\n",
    "    view_matrix=extrinsic_matrix.T,\n",
    ")\n",
    "\n",
    "fovX = torch.Tensor([2 * math.atan(width / (2 * focal_x))])\n",
    "fovY = torch.Tensor([2 * math.atan(height / (2 * focal_y))])\n",
    "\n",
    "\n",
    "covariance_2d = compute_2d_covariance(\n",
    "    points=gaussians.points[in_view],\n",
    "    extrinsic_matrix=extrinsic_matrix.T,\n",
    "    covariance_3d=covariance_3d[in_view],\n",
    "    tan_fovY=torch.tan(fovX / 2),\n",
    "    tan_fovX=torch.tan(fovX / 2),\n",
    "    focal_x=focal_x,\n",
    "    focal_y=focal_y,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
