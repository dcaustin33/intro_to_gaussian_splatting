{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 4.5000e-09],\n",
       "         [4.5000e-09, 1.0000e+00]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def project_points(projection_matrix: torch.Tensor, points: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Projection matrix is a 3x4 matrix, points is a Nx3 matrix. Returns a Nx2 matrix\"\"\"\n",
    "    points = torch.cat(\n",
    "        [points, torch.ones(points.shape[0], 1, device=points.device)], dim=1\n",
    "    )\n",
    "    projected_points = torch.matmul(projection_matrix, points.t()).t()\n",
    "    projected_points = projected_points[:, :2] / projected_points[:, 2].unsqueeze(1)\n",
    "    return projected_points\n",
    "\n",
    "\n",
    "def getWorld2View(R: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    Rt = torch.zeros((4, 4))\n",
    "    Rt[:3, :3] = R.t()\n",
    "    Rt[:3, 3] = t\n",
    "    Rt[3, 3] = 1.0\n",
    "    return Rt\n",
    "\n",
    "\n",
    "def get_points_and_covariance(\n",
    "    points: torch.Tensor,\n",
    "    covariance_3d: torch.Tensor,\n",
    "    extrinsic_matrix: torch.Tensor,\n",
    "    intrinsic_matrix: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Given a set of points, we project to 2d and find their 2d covariance matrices\n",
    "\n",
    "    Args:\n",
    "        points: Nx3 tensor of points, will add a 4th dimension for homogeneous coordinates\n",
    "        covariance_3d: Nx3x3 tensor of covariance matrices\n",
    "        extrinsic_matrix: 4x4 tensor translates the points to camera coordinates but still in 3d\n",
    "        intrinsic_matrix: 3x4 tensor that projects the points to 2d\n",
    "    \"\"\"\n",
    "    points = torch.cat([points, torch.ones(points.shape[0], 1, device=points.device)], dim=1)\n",
    "    # results in a 4xN tensor\n",
    "    points_in_camera_coords = torch.matmul(extrinsic_matrix, points.t()).T  # Nx4\n",
    "    # do not need to divide by 1 as this is always 1\n",
    "    final_points_in_camera_coords = points_in_camera_coords[:, :3] / points_in_camera_coords[\n",
    "        :, 3\n",
    "    ].unsqueeze(1)\n",
    "    # now we project to 2d\n",
    "    projected_points = project_points(intrinsic_matrix, final_points_in_camera_coords)\n",
    "    # now we find the covariance matrices in 2d\n",
    "    projected_covariance = []\n",
    "    \n",
    "    f_x = intrinsic_matrix[0, 0]\n",
    "    f_y = intrinsic_matrix[1, 1]\n",
    "    \n",
    "    # this makes it stored in column major order - something the original code does\n",
    "    _W = getWorld2View(extrinsic_matrix[:3, :3], extrinsic_matrix[:3, 3]).transpose(0, 1)\n",
    "    W = torch.Tensor([\n",
    "        [_W[0, 0], _W[1, 0], _W[2, 0]],\n",
    "        [_W[0, 1], _W[1, 1], _W[2, 1]],\n",
    "        [_W[0, 2], _W[1, 2], _W[2, 2]],\n",
    "    ])\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(covariance_3d.shape[0]):\n",
    "        covariance = covariance_3d[i]\n",
    "        camera_coords_x = points_in_camera_coords[i, 0]\n",
    "        camera_coords_y = points_in_camera_coords[i, 1]\n",
    "        camera_coords_z = points_in_camera_coords[i, 2]\n",
    "        jacobian = torch.zeros((3, 3), device=points.device)\n",
    "        jacobian[0, 0] = f_x / camera_coords_z\n",
    "        jacobian[1, 1] = f_y / camera_coords_z\n",
    "        jacobian[0, 2] = -f_x * camera_coords_x / (camera_coords_z ** 2)\n",
    "        jacobian[1, 2] = -f_y * camera_coords_y / (camera_coords_z ** 2)\n",
    "        T = torch.matmul(jacobian, W)\n",
    "        final_variance = torch.matmul(T, torch.matmul(covariance, T.t()))\n",
    "        projected_covariance.append(final_variance[:2, :2])\n",
    "    return projected_points, torch.stack(projected_covariance)\n",
    "\n",
    "\n",
    "points = torch.Tensor([\n",
    "    [1.5, 3, 1],\n",
    "])\n",
    "\n",
    "covariance = torch.Tensor([[\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, .000000001],\n",
    "]])\n",
    "extrinsic_matrix = torch.Tensor([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "intrinsic_matrix = torch.Tensor([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "])\n",
    "\n",
    "projected_points, projected_covariance = get_points_and_covariance(\n",
    "    points, covariance, extrinsic_matrix, intrinsic_matrix\n",
    ")\n",
    "projected_covariance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
